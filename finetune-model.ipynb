{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wongyenchik/anaconda3/envs/finetune-model/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import interpreter_login\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv(\"/Users/wongyenchik/Desktop/finetune llama/.env\")\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_KEY\")\n",
    "region_name = os.getenv(\"AWS_REGION\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "import subprocess\n",
    "import boto3\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_dataset_name = \"HuggingFaceH4/MATH-500\"\n",
    "dataset = load_dataset(huggingface_dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\\\theta),$ where $r > 0$ and $0 \\\\le \\\\theta < 2 \\\\pi.$',\n",
       " 'solution': 'We have that $r = \\\\sqrt{0^2 + 3^2} = 3.$  Also, if we draw the line connecting the origin and $(0,3),$ this line makes an angle of $\\\\frac{\\\\pi}{2}$ with the positive $x$-axis.\\n\\n[asy]\\nunitsize(0.8 cm);\\n\\ndraw((-0.5,0)--(3.5,0));\\ndraw((0,-0.5)--(0,3.5));\\ndraw(arc((0,0),3,0,90),red,Arrow(6));\\n\\ndot((0,3), red);\\nlabel(\"$(0,3)$\", (0,3), W);\\ndot((3,0), red);\\n[/asy]\\n\\nTherefore, the polar coordinates are $\\\\boxed{\\\\left( 3, \\\\frac{\\\\pi}{2} \\\\right)}.$',\n",
       " 'answer': '\\\\left( 3, \\\\frac{\\\\pi}{2} \\\\right)'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'] = dataset['test'].remove_columns(['subject', 'level', 'unique_id'])\n",
    "\n",
    "# Check the result to see if the 'input' column is removed\n",
    "dataset['test'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_test = 100\n",
    "num_val = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_list = []\n",
    "response_list = []\n",
    "\n",
    "for line in dataset['test']:\n",
    "    instruction_list.append(line['problem'])\n",
    "    response_list.append(line['solution'] + \" The answer is:\" + line['answer'] + \" -MathGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We count the number of times $\\\\frac{1}{n^3}$ appears in the sum\\n\\\\[\\\\sum_{j = 1}^\\\\infty \\\\sum_{k = 1}^\\\\infty \\\\frac{1}{(j + k)^3},\\\\]where $n$ is a fixed positive integer.  (In other words, we are conditioning the sum on $j + k$.)  We get a term of $\\\\frac{1}{n^3}$ each time $j + k = n.$  The pairs $(j,k)$ that work are $(1,n - 1),$ $(2,n - 2),$ $\\\\dots,$ $(n - 1,1),$ for a total of $n - 1$ pairs.  Therefore,\\n\\\\begin{align*}\\n\\\\sum_{j = 1}^\\\\infty \\\\sum_{k = 1}^\\\\infty \\\\frac{1}{(j + k)^3} &= \\\\sum_{n = 1}^\\\\infty \\\\frac{n - 1}{n^3} \\\\\\\\\\n&= \\\\sum_{n = 1}^\\\\infty \\\\left( \\\\frac{n}{n^3} - \\\\frac{1}{n^3} \\\\right) \\\\\\\\\\n&= \\\\sum_{n = 1}^\\\\infty \\\\left( \\\\frac{1}{n^2} - \\\\frac{1}{n^3} \\\\right) \\\\\\\\\\n&= \\\\sum_{n = 1}^\\\\infty \\\\frac{1}{n^2} - \\\\sum_{n = 1}^\\\\infty \\\\frac{1}{n^3} \\\\\\\\\\n&= \\\\boxed{p - q}.\\n\\\\end{align*} The answer is:p - q -MathGPT'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instruction_list[0]\n",
    "response_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '<s>[INST] MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always provide the students steps to solve the question before provide answer. It reacts to feedback aptly and ends responses with its signature \\'MathGPT\\'. MathGPT will tailor the length of its responses to match the student\\'s questions, providing concise acknowledgments to brief expressions of gratitude or feedback, thus keeping the interaction natural and engaging.\\n\\nPlease respond to the following comment.\\n \\nAltitudes $\\\\overline{AD}$ and $\\\\overline{BE}$ of $\\\\triangle ABC$ intersect at $H$.  If $\\\\angle BAC = 54^\\\\circ$ and $\\\\angle ABC = 52^\\\\circ$, then what is $\\\\angle AHB$? \\n[/INST]\\nFirst, we build a diagram:\\n\\n[asy]\\n\\nsize(150); defaultpen(linewidth(0.8));\\n\\npair B = (0,0), C = (3,0), A = (1.8,2), P = foot(A,B,C), Q = foot(B,A,C),H = intersectionpoint(B--Q,A--P);\\n\\ndraw(A--B--C--cycle);\\n\\ndraw(A--P^^B--Q);\\n\\nlabel(\"$A$\",A,N); label(\"$B$\",B,W); label(\"$C$\",C,E); label(\"$D$\",P,S); label(\"$E$\",Q,E); label(\"$H$\",H,NW);\\n\\ndraw(rightanglemark(C,P,H,3.5));\\n\\ndraw(rightanglemark(H,Q,C,3.5));\\n\\n[/asy]\\n\\nWe have $\\\\angle AHB = \\\\angle DHE$, and from quadrilateral $CDHE$, we have  \\\\begin{align*}\\n\\\\angle DHE &= 360^\\\\circ - \\\\angle HEC - \\\\angle ECD - \\\\angle CDH \\\\\\\\\\n&= 360^\\\\circ - 90^\\\\circ - \\\\angle ACB - 90^\\\\circ\\\\\\\\\\n&= 180^\\\\circ - \\\\angle ACB.\\n\\\\end{align*}From triangle $ABC$, we have $180^\\\\circ - \\\\angle ACB = \\\\angle BAC + \\\\angle ABC = 54^\\\\circ + 52^\\\\circ = \\\\boxed{106^\\\\circ}$. The answer is:106^\\\\circ -MathGPT</s>'}\n"
     ]
    }
   ],
   "source": [
    "# prompt format\n",
    "intstructions_string = f\"\"\"MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always provide the students steps to solve the question before provide answer. \\\n",
    "It reacts to feedback aptly and ends responses with its signature 'MathGPT'. \\\n",
    "MathGPT will tailor the length of its responses to match the student's questions, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\n",
    "\n",
    "Please respond to the following comment.\n",
    "\"\"\"\n",
    "\n",
    "example_template = lambda comment, response: f'''<s>[INST] {intstructions_string} \\n{comment} \\n[/INST]\\n''' + response + \"</s>\"\n",
    "\n",
    "example_list = []\n",
    "for i in range(len(instruction_list)):\n",
    "    example = {\"text\":example_template(instruction_list[i],response_list[i])}\n",
    "    example_list.append(example)\n",
    "\n",
    "print(example_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test and val data\n",
    "test_val_index_list = random.sample(range(0, len(example_list)-1), num_test+num_val)\n",
    "\n",
    "test_list = [example_list[index] for index in test_val_index_list[:num_test]]\n",
    "val_list = [example_list[index] for index in test_val_index_list[num_test:]]\n",
    "\n",
    "for example in test_list+val_list:\n",
    "    example_list.remove(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store train, test and valid data as jsonl as MLX model required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "with open('data/train.jsonl', 'w') as outfile:\n",
    "    for example in example_list:\n",
    "        json.dump(example, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test.jsonl', 'w') as outfile:\n",
    "    for example in test_list:\n",
    "        json.dump(example, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/valid.jsonl', 'w') as outfile:\n",
    "    for example in val_list:\n",
    "        json.dump(example, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "# Upload function\n",
    "def upload_to_s3(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket inside a specific folder\"\"\"\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    s3.upload_file(file_name, bucket, object_name)\n",
    "    print(f\"File '{file_name}' uploaded successfully to '{bucket}/{object_name}'\")\n",
    "    return True\n",
    "\n",
    "# Local file path\n",
    "file_names = ['data/train.jsonl', 'data/test.jsonl', 'data/valid.jsonl']\n",
    "\n",
    "# S3 bucket name and S3 folder\n",
    "bucket_name = 'finetune-model-layer'\n",
    "s3_folder = 'data'  # This is the folder in the S3 bucket\n",
    "\n",
    "for file_name in file_names:\n",
    "    # Specify the full S3 object name (key)\n",
    "    object_name = f\"{s3_folder}/{file_name.split('/')[-1]}\"\n",
    "\n",
    "    # Upload the file to S3\n",
    "    upload_to_s3(file_name, bucket_name, object_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"google/gemma-2-2b-it\"\n",
    "command = [\n",
    "    'python', '-m', 'mlx_lm.convert', '--hf-path', model , '-q'\n",
    "]\n",
    "subprocess.run(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lora layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define variables\n",
    "model = \"mlx_model\"\n",
    "iters = 10\n",
    "steps_per_eval = 20\n",
    "val_batches = -1\n",
    "learning_rate = 1e-5\n",
    "adapter_path = \"adapter-2\"\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "# Define MLflow experiment\n",
    "mlflow.set_experiment(\"MLX LoRA Fine-Tuning\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"MLX-Model-LoRA-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"):\n",
    "\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param(\"model\", model)\n",
    "    mlflow.log_param(\"iters\", iters)\n",
    "    mlflow.log_param(\"steps_per_eval\", steps_per_eval)\n",
    "    mlflow.log_param(\"val_batches\", val_batches)\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"adapter_path\", adapter_path)\n",
    "\n",
    "    # Create the command list\n",
    "    command = [\n",
    "        'python', '-m', 'mlx_lm.lora', '--model', model, '--train',\n",
    "        '--iters', str(iters),\n",
    "        '--steps-per-eval', str(steps_per_eval),\n",
    "        '--val-batches', str(val_batches),\n",
    "        '--learning-rate', str(learning_rate),\n",
    "        '--test', \n",
    "        '--adapter-path', adapter_path\n",
    "    ]\n",
    "    \n",
    "    # Run the subprocess command to execute fine-tuning\n",
    "    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store lora layer at s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "# Upload function\n",
    "def upload_to_s3(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket inside a specific folder\"\"\"\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    s3.upload_file(file_name, bucket, object_name)\n",
    "    print(f\"File '{file_name}' uploaded successfully to '{bucket}/{object_name}'\")\n",
    "    return True\n",
    "\n",
    "# Local file path\n",
    "folder_name = 'adapters'\n",
    "\n",
    "# S3 bucket name and S3 folder\n",
    "bucket_name = 'finetune-model-layer'\n",
    "s3_folder = 'lora_layer'  # This is the folder in the S3 bucket\n",
    "\n",
    "# Loop through all files in the adapters folder\n",
    "for root, dirs, files in os.walk(folder_name):\n",
    "    for file in files:\n",
    "        # Get the full file path\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        # Create the object name by preserving the folder structure\n",
    "        object_name = os.path.join(s3_folder, os.path.relpath(file_path, folder_name)).replace(\"\\\\\", \"/\")\n",
    "        \n",
    "        # Upload the file to S3\n",
    "        upload_to_s3(file_path, bucket_name, object_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the ai (human evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt format\n",
    "intstructions_string = f\"\"\"MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always provide the students steps to solve the question before provide answer. \\\n",
    "It reacts to feedback aptly and ends responses with its signature 'MathGPT'. \\\n",
    "MathGPT will tailor the length of its responses to match the student's questions, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\n",
    "\n",
    "Please respond to the following comment.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = lambda comment: f'''<s>[INST] {intstructions_string} \\n{comment} \\n[/INST]\\n'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define variables\n",
    "comment = \"In 1992, a scoop of gelato could be purchased in Italy for 1200 lire. The same gelato would have cost $\\\\$1.50$ in the U.S. At the equivalent exchange rate between the lire and the dollar, how many dollars would be equivalent to 1,000,000 lire?\"\n",
    "\n",
    "# Generate the prompt using the comment\n",
    "prompt = prompt_template(comment)\n",
    "\n",
    "# Create the command list\n",
    "command = [\n",
    "    'python', '-m', 'mlx_lm.generate',\n",
    "    '--model', 'mlx_model',\n",
    "    '--adapter-path', 'adapters',\n",
    "    '--max-tokens', '512',\n",
    "    '--prompt', prompt\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "comment = \"In 1992, a scoop of gelato could be purchased in Italy for 1200 lire. The same gelato would have cost $\\\\$1.50$ in the U.S. At the equivalent exchange rate between the lire and the dollar, how many dollars would be equivalent to 1,000,000 lire?\"\n",
    "\n",
    "# Generate the prompt using the comment\n",
    "prompt = prompt_template(comment)\n",
    "\n",
    "# Create the command list\n",
    "command = [\n",
    "    'python', '-m', 'mlx_lm.generate',\n",
    "    '--model', 'mlx_model',\n",
    "    '--max-tokens', '512',\n",
    "    '--prompt', prompt\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the response with openai and store in MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>By the associative property of multiplication,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Since $10^x - 10 = 9990,$ we have $$10^x = 999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Squaring both sides, we get\\n\\[x + \\sqrt{3x + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Setting $x = 0,$ we get $|c| \\le 1.$  Setting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Let $\\mathbf{v} = \\begin{pmatrix} a \\\\ b \\\\ c ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>We count the number of times $\\frac{1}{n^3}$ a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>We can write\\n\\begin{align*}\\n\\frac{1}{\\cos^2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Let $s_1 = x + y + z$ and $s_2 = xy + xz + yz....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>The hexagon has a side length of 16 centimeter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Suppose that $\\angle ADC = x^\\circ$. The area ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0  MathGPT, functioning as a virtual Math chatbot...   \n",
       "1  MathGPT, functioning as a virtual Math chatbot...   \n",
       "2  MathGPT, functioning as a virtual Math chatbot...   \n",
       "3  MathGPT, functioning as a virtual Math chatbot...   \n",
       "4  MathGPT, functioning as a virtual Math chatbot...   \n",
       "5  MathGPT, functioning as a virtual Math chatbot...   \n",
       "6  MathGPT, functioning as a virtual Math chatbot...   \n",
       "7  MathGPT, functioning as a virtual Math chatbot...   \n",
       "8  MathGPT, functioning as a virtual Math chatbot...   \n",
       "9  MathGPT, functioning as a virtual Math chatbot...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  By the associative property of multiplication,...  \n",
       "1  Since $10^x - 10 = 9990,$ we have $$10^x = 999...  \n",
       "2  Squaring both sides, we get\\n\\[x + \\sqrt{3x + ...  \n",
       "3  Setting $x = 0,$ we get $|c| \\le 1.$  Setting ...  \n",
       "4  Let $\\mathbf{v} = \\begin{pmatrix} a \\\\ b \\\\ c ...  \n",
       "5  We count the number of times $\\frac{1}{n^3}$ a...  \n",
       "6  We can write\\n\\begin{align*}\\n\\frac{1}{\\cos^2 ...  \n",
       "7  Let $s_1 = x + y + z$ and $s_2 = xy + xz + yz....  \n",
       "8  The hexagon has a side length of 16 centimeter...  \n",
       "9  Suppose that $\\angle ADC = x^\\circ$. The area ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the test dataset (without the response)\n",
    "inputs = []\n",
    "ground_truth = []\n",
    "\n",
    "# Go through each example in test_list\n",
    "for example in test_list:\n",
    "    # Extract the comment part from the 'text' field (everything between [INST] and [/INST])\n",
    "    inst_start = example['text'].find(\"[INST]\") + len(\"[INST]\")\n",
    "    inst_end = example['text'].find(\"[/INST]\")\n",
    "\n",
    "    # Extract the comment (instruction) and the response\n",
    "    questions = example['text'][inst_start:inst_end].strip()  # This is the prompt for the test data\n",
    "    response = example['text'][inst_end + len(\"[/INST]\"):-4].strip()  # This is the corresponding answer\n",
    "\n",
    "    # Append to inputs and ground truth\n",
    "    inputs.append(questions)\n",
    "    ground_truth.append(response)\n",
    "\n",
    "# Convert inputs and ground_truth to a DataFrame\n",
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"inputs\": inputs,        \n",
    "        \"ground_truth\": ground_truth\n",
    "    }\n",
    ")\n",
    "\n",
    "# Example to see the eval_data\n",
    "eval_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the structure of MLX model in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wongyenchik/anaconda3/envs/finetune-model/lib/python3.13/site-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "import subprocess\n",
    "\n",
    "class MLXModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        # Store the model path, which will be used later in the prediction step\n",
    "        self.model_path = context.artifacts[\"model\"]\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        # Log the input type\n",
    "        print(f\"Input type: {type(model_input)}\")\n",
    "        print(f\"Input data: {model_input}\")\n",
    "\n",
    "        # Check if the input is a DataFrame and extract the 'inputs' column\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            if 'inputs' in model_input.columns:\n",
    "                # Loop through the DataFrame and process each row\n",
    "                responses = []\n",
    "                for comment in model_input['inputs']:\n",
    "                    prompt = self.prompt_template(comment)\n",
    "\n",
    "                    command = [\n",
    "                        'python', '-m', 'mlx_lm.generate',\n",
    "                        '--model', self.model_path,  # Use the stored model path from load_context\n",
    "                        '--max-tokens', '512',\n",
    "                        '--prompt', prompt\n",
    "                    ]\n",
    "\n",
    "                    # Run the command to generate the response\n",
    "                    result = subprocess.run(command, capture_output=True, text=True)\n",
    "                    responses.append(result.stdout)\n",
    "                return responses\n",
    "            else:\n",
    "                raise ValueError(\"Expected 'inputs' column in the DataFrame.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected input type: {type(model_input)}\")\n",
    "\n",
    "    def prompt_template(self, comment):\n",
    "        # Custom prompt template\n",
    "        instructions_string = \"\"\"MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always providing the students steps to solve the question before providing the answer. \\\n",
    "It reacts to feedback aptly and ends responses with its signature 'MathGPT'. \\\n",
    "MathGPT will tailor the length of its responses to match the student's questions, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\n",
    "Please respond to the following comment.\n",
    "\"\"\"\n",
    "        return f'''<s>[INST] {instructions_string} \\n{comment} \\n[/INST]\\n'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log the model in MLFlow and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 22:29:07 INFO mlflow.tracking.fluent: Experiment with name 'LLM Evaluation' does not exist. Creating a new experiment.\n",
      "2025/03/05 22:29:07 INFO mlflow.pyfunc: Validating input example against model signature\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 15.22it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "0  [INST] MathGPT, functioning as a virtual Math ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:30<00:00,  1.06it/s]  \n",
      "2025/03/05 22:30:15 INFO mlflow.models.evaluation.utils.trace: Auto tracing is temporarily enabled during the model evaluation for computing some metrics and debugging. To disable tracing, call `mlflow.autolog(disable=True)`.\n",
      "2025/03/05 22:30:15 INFO mlflow.models.evaluation.evaluators.default: Computing model predictions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "0  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "1  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "2  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "3  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "4  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "5  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "6  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "7  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "8  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "9  MathGPT, functioning as a virtual Math chatbot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 22:34:42 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "Device set to use mps:0\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.12s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:09<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlflow.models.evaluation.base.EvaluationResult object at 0x2ae240cd0>\n",
      "üèÉ View run mysterious-midge-856 at: http://127.0.0.1:5000/#/experiments/880270386239245598/runs/963ef29d73b34430959321a914b68a5e\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/880270386239245598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mlflow.metrics import latency\n",
    "from mlflow.metrics.genai import answer_correctness\n",
    "import time\n",
    "import mlflow\n",
    "signature = mlflow.models.infer_signature(\n",
    "    model_input=pd.DataFrame({\n",
    "    'inputs': [\n",
    "        \"[INST] MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always providing steps before the answer. ...\",\n",
    "    ]\n",
    "}),\n",
    "    model_output=[\"==========\\nLet's solve that!  \\n\\nTo find the answer, we simply add the numbers together: 4 + 4 = 8. \\n\\nSo, 4 + 4 = 8. \\n\\nMathGPT \\n\\n==========\\nPrompt: 119 tokens, 102.358 tokens-per-sec\\nGeneration: 49 tokens, 15.268 tokens-per-sec\\nPeak memory: 1.713 GB\\n\",\n",
    " \"==========\\nTo find the derivative of x¬≤, we use the power rule of differentiation.  \\n\\nThe power rule states that the derivative of x<sup>n</sup> is nx<sup>n-1</sup>.\\n\\nApplying this to x¬≤:\\n\\n*  The derivative of x¬≤ is 2x<sup>2-1</sup> \\n*  Simplifying, we get 2x<sup>1</sup> \\n*  Therefore, the derivative of x¬≤ is **2x**. \\n\\n\\nMathGPT \\n\\n==========\\nPrompt: 120 tokens, 118.289 tokens-per-sec\\nGeneration: 99 tokens, 18.342 tokens-per-sec\\nPeak memory: 1.714 GB\\n\"],\n",
    ")\n",
    "input_example = pd.DataFrame({\n",
    "    'inputs': [\n",
    "        \"[INST] MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always providing steps before the answer. ...\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "# The evaluation process remains the same\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "mlflow.set_experiment(\"LLM Evaluation\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    logged_model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",  # Path where the model will be stored in MLflow\n",
    "        python_model=MLXModelWrapper(),  # Your custom model wrapper\n",
    "        artifacts={\"model\": \"/Users/wongyenchik/Desktop/finetune llama/my-model\"},  # The path to your saved MLX model\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )\n",
    "\n",
    "    # Use the function to evaluate the model\n",
    "    results = mlflow.evaluate(\n",
    "        logged_model_info.model_uri,\n",
    "        data=eval_data[:10],\n",
    "        targets=\"ground_truth\",\n",
    "        model_type=\"question-answering\",\n",
    "        extra_metrics=[\n",
    "            answer_correctness(),\n",
    "            latency(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Example output DataFrame for inspection\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model and push to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "save_path = \"my-model\"\n",
    "\n",
    "# Create the command list\n",
    "command = [\n",
    "    'python', '-m', 'mlx_lm.fuse',\n",
    "    '--model', 'mlx_model',\n",
    "    '--save-path', save_path,\n",
    "    '--adapter-path', 'adapters',\n",
    "    '--upload-repo', 'yenchik/mlx-gemma-2-2b-it-math',\n",
    "    '--hf-path', 'google/gemma-2-2b-it'\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load(\"yenchik/mlx-gemma-2-2b-it-math\")\n",
    "\n",
    "prompt = \"In 1992, a scoop of gelato could be purchased in Italy for 1200 lire. The same gelato would have cost $\\\\$1.50$ in the U.S. At the equivalent exchange rate between the lire and the dollar, how many dollars would be equivalent to 1,000,000 lire?\"\n",
    "if tokenizer.chat_template is not None:\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
