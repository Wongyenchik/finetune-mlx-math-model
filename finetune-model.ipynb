{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import interpreter_login\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv(\"/Users/wongyenchik/Documents/GitHub/finetune-mlx-math-model/.env\")\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_KEY\")\n",
    "region_name = os.getenv(\"AWS_REGION\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "import subprocess\n",
    "import boto3\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 500/500 [00:00<00:00, 61828.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "huggingface_dataset_name = \"HuggingFaceH4/MATH-500\"\n",
    "dataset = load_dataset(huggingface_dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\\\theta),$ where $r > 0$ and $0 \\\\le \\\\theta < 2 \\\\pi.$',\n",
       " 'solution': 'We have that $r = \\\\sqrt{0^2 + 3^2} = 3.$  Also, if we draw the line connecting the origin and $(0,3),$ this line makes an angle of $\\\\frac{\\\\pi}{2}$ with the positive $x$-axis.\\n\\n[asy]\\nunitsize(0.8 cm);\\n\\ndraw((-0.5,0)--(3.5,0));\\ndraw((0,-0.5)--(0,3.5));\\ndraw(arc((0,0),3,0,90),red,Arrow(6));\\n\\ndot((0,3), red);\\nlabel(\"$(0,3)$\", (0,3), W);\\ndot((3,0), red);\\n[/asy]\\n\\nTherefore, the polar coordinates are $\\\\boxed{\\\\left( 3, \\\\frac{\\\\pi}{2} \\\\right)}.$',\n",
       " 'answer': '\\\\left( 3, \\\\frac{\\\\pi}{2} \\\\right)'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'] = dataset['test'].remove_columns(['subject', 'level', 'unique_id'])\n",
    "\n",
    "# Check the result to see if the 'input' column is removed\n",
    "dataset['test'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_test = 100\n",
    "num_val = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_list = []\n",
    "response_list = []\n",
    "\n",
    "for line in dataset['test']:\n",
    "    instruction_list.append(line['problem'])\n",
    "    response_list.append(line['solution'] + \" The answer is:\" + line['answer'] + \" -MathGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We count the number of times $\\\\frac{1}{n^3}$ appears in the sum\\n\\\\[\\\\sum_{j = 1}^\\\\infty \\\\sum_{k = 1}^\\\\infty \\\\frac{1}{(j + k)^3},\\\\]where $n$ is a fixed positive integer.  (In other words, we are conditioning the sum on $j + k$.)  We get a term of $\\\\frac{1}{n^3}$ each time $j + k = n.$  The pairs $(j,k)$ that work are $(1,n - 1),$ $(2,n - 2),$ $\\\\dots,$ $(n - 1,1),$ for a total of $n - 1$ pairs.  Therefore,\\n\\\\begin{align*}\\n\\\\sum_{j = 1}^\\\\infty \\\\sum_{k = 1}^\\\\infty \\\\frac{1}{(j + k)^3} &= \\\\sum_{n = 1}^\\\\infty \\\\frac{n - 1}{n^3} \\\\\\\\\\n&= \\\\sum_{n = 1}^\\\\infty \\\\left( \\\\frac{n}{n^3} - \\\\frac{1}{n^3} \\\\right) \\\\\\\\\\n&= \\\\sum_{n = 1}^\\\\infty \\\\left( \\\\frac{1}{n^2} - \\\\frac{1}{n^3} \\\\right) \\\\\\\\\\n&= \\\\sum_{n = 1}^\\\\infty \\\\frac{1}{n^2} - \\\\sum_{n = 1}^\\\\infty \\\\frac{1}{n^3} \\\\\\\\\\n&= \\\\boxed{p - q}.\\n\\\\end{align*} The answer is:p - q -MathGPT'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instruction_list[0]\n",
    "response_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '<s>[INST] MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always provide the students steps to solve the question before provide answer. It reacts to feedback aptly and ends responses with its signature \\'MathGPT\\'. MathGPT will tailor the length of its responses to match the student\\'s questions, providing concise acknowledgments to brief expressions of gratitude or feedback, thus keeping the interaction natural and engaging.\\n\\nPlease respond to the following comment.\\n \\nAltitudes $\\\\overline{AD}$ and $\\\\overline{BE}$ of $\\\\triangle ABC$ intersect at $H$.  If $\\\\angle BAC = 54^\\\\circ$ and $\\\\angle ABC = 52^\\\\circ$, then what is $\\\\angle AHB$? \\n[/INST]\\nFirst, we build a diagram:\\n\\n[asy]\\n\\nsize(150); defaultpen(linewidth(0.8));\\n\\npair B = (0,0), C = (3,0), A = (1.8,2), P = foot(A,B,C), Q = foot(B,A,C),H = intersectionpoint(B--Q,A--P);\\n\\ndraw(A--B--C--cycle);\\n\\ndraw(A--P^^B--Q);\\n\\nlabel(\"$A$\",A,N); label(\"$B$\",B,W); label(\"$C$\",C,E); label(\"$D$\",P,S); label(\"$E$\",Q,E); label(\"$H$\",H,NW);\\n\\ndraw(rightanglemark(C,P,H,3.5));\\n\\ndraw(rightanglemark(H,Q,C,3.5));\\n\\n[/asy]\\n\\nWe have $\\\\angle AHB = \\\\angle DHE$, and from quadrilateral $CDHE$, we have  \\\\begin{align*}\\n\\\\angle DHE &= 360^\\\\circ - \\\\angle HEC - \\\\angle ECD - \\\\angle CDH \\\\\\\\\\n&= 360^\\\\circ - 90^\\\\circ - \\\\angle ACB - 90^\\\\circ\\\\\\\\\\n&= 180^\\\\circ - \\\\angle ACB.\\n\\\\end{align*}From triangle $ABC$, we have $180^\\\\circ - \\\\angle ACB = \\\\angle BAC + \\\\angle ABC = 54^\\\\circ + 52^\\\\circ = \\\\boxed{106^\\\\circ}$. The answer is:106^\\\\circ -MathGPT</s>'}\n"
     ]
    }
   ],
   "source": [
    "# prompt format\n",
    "intstructions_string = f\"\"\"MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always provide the students steps to solve the question before provide answer. \\\n",
    "It reacts to feedback aptly and ends responses with its signature 'MathGPT'. \\\n",
    "MathGPT will tailor the length of its responses to match the student's questions, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\n",
    "\n",
    "Please respond to the following comment.\n",
    "\"\"\"\n",
    "\n",
    "example_template = lambda comment, response: f'''<s>[INST] {intstructions_string} \\n{comment} \\n[/INST]\\n''' + response + \"</s>\"\n",
    "\n",
    "example_list = []\n",
    "for i in range(len(instruction_list)):\n",
    "    example = {\"text\":example_template(instruction_list[i],response_list[i])}\n",
    "    example_list.append(example)\n",
    "\n",
    "print(example_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test and val data\n",
    "test_val_index_list = random.sample(range(0, len(example_list)-1), num_test+num_val)\n",
    "\n",
    "test_list = [example_list[index] for index in test_val_index_list[:num_test]]\n",
    "val_list = [example_list[index] for index in test_val_index_list[num_test:]]\n",
    "\n",
    "for example in test_list+val_list:\n",
    "    example_list.remove(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store train, test and valid data as jsonl as MLX model required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "with open('data/train.jsonl', 'w') as outfile:\n",
    "    for example in example_list:\n",
    "        json.dump(example, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test.jsonl', 'w') as outfile:\n",
    "    for example in test_list:\n",
    "        json.dump(example, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/valid.jsonl', 'w') as outfile:\n",
    "    for example in val_list:\n",
    "        json.dump(example, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoCredentialsError",
     "evalue": "Unable to locate credentials",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNoCredentialsError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m object_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name.split(\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Upload the file to S3\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mupload_to_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mupload_to_s3\u001b[39m\u001b[34m(file_name, bucket, object_name)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m object_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     13\u001b[39m     object_name = file_name\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43ms3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m uploaded successfully to \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/context.py:124\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    123\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/boto3/s3/inject.py:170\u001b[39m, in \u001b[36mupload_file\u001b[39m\u001b[34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[32m    136\u001b[39m \n\u001b[32m    137\u001b[39m \u001b[33;03mUsage::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m \u001b[33;03m    transfer.\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/boto3/s3/transfer.py:372\u001b[39m, in \u001b[36mS3Transfer.upload_file\u001b[39m\u001b[34m(self, filename, bucket, key, callback, extra_args)\u001b[39m\n\u001b[32m    368\u001b[39m future = \u001b[38;5;28mself\u001b[39m._manager.upload(\n\u001b[32m    369\u001b[39m     filename, bucket, key, extra_args, subscribers\n\u001b[32m    370\u001b[39m )\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# client error.\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/s3transfer/futures.py:111\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    108\u001b[39m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[32m    109\u001b[39m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[32m    110\u001b[39m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    113\u001b[39m         \u001b[38;5;28mself\u001b[39m.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/s3transfer/futures.py:272\u001b[39m, in \u001b[36mTransferCoordinator.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/s3transfer/tasks.py:142\u001b[39m, in \u001b[36mTask.__call__\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# If the task is not done (really only if some other related\u001b[39;00m\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# task to the TransferFuture had failed) then execute the task's\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# main() method.\u001b[39;00m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transfer_coordinator.done():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    144\u001b[39m     \u001b[38;5;28mself\u001b[39m._log_and_set_exception(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/s3transfer/tasks.py:165\u001b[39m, in \u001b[36mTask._execute_main\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# Log what is about to be executed.\u001b[39;00m\n\u001b[32m    163\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuting task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs_to_display\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m return_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# If the task is the final task, then set the TransferFuture's\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# value to the return value from main().\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_final:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/s3transfer/upload.py:796\u001b[39m, in \u001b[36mPutObjectTask._main\u001b[39m\u001b[34m(self, client, fileobj, bucket, key, extra_args)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    788\u001b[39m \u001b[33;03m:param client: The client to use when calling PutObject\u001b[39;00m\n\u001b[32m    789\u001b[39m \u001b[33;03m:param fileobj: The file to upload.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    793\u001b[39m \u001b[33;03m    used in the upload.\u001b[39;00m\n\u001b[32m    794\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    795\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m fileobj \u001b[38;5;28;01mas\u001b[39;00m body:\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m     \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/client.py:570\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    567\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    568\u001b[39m     )\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/context.py:124\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    123\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/client.py:1013\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1009\u001b[39m     maybe_compress_request(\n\u001b[32m   1010\u001b[39m         \u001b[38;5;28mself\u001b[39m.meta.config, request_dict, operation_model\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1012\u001b[39m     apply_request_checksum(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m     http, parsed_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_context\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28mself\u001b[39m.meta.events.emit(\n\u001b[32m   1018\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter-call.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1019\u001b[39m     http_response=http,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     context=request_context,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http.status_code >= \u001b[32m300\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/client.py:1037\u001b[39m, in \u001b[36mBaseClient._make_request\u001b[39m\u001b[34m(self, operation_model, request_dict, request_context)\u001b[39m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_endpoint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1039\u001b[39m         \u001b[38;5;28mself\u001b[39m.meta.events.emit(\n\u001b[32m   1040\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mafter-call-error.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._service_model.service_id.hyphenize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_model.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1041\u001b[39m             exception=e,\n\u001b[32m   1042\u001b[39m             context=request_context,\n\u001b[32m   1043\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/endpoint.py:119\u001b[39m, in \u001b[36mEndpoint.make_request\u001b[39m\u001b[34m(self, operation_model, request_dict)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict):\n\u001b[32m    114\u001b[39m     logger.debug(\n\u001b[32m    115\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMaking request for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m with params: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    116\u001b[39m         operation_model,\n\u001b[32m    117\u001b[39m         request_dict,\n\u001b[32m    118\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/endpoint.py:196\u001b[39m, in \u001b[36mEndpoint._send_request\u001b[39m\u001b[34m(self, request_dict, operation_model)\u001b[39m\n\u001b[32m    194\u001b[39m context = request_dict[\u001b[33m'\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    195\u001b[39m \u001b[38;5;28mself\u001b[39m._update_retries_context(context, attempts)\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m success_response, exception = \u001b[38;5;28mself\u001b[39m._get_response(\n\u001b[32m    198\u001b[39m     request, operation_model, context\n\u001b[32m    199\u001b[39m )\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._needs_retry(\n\u001b[32m    201\u001b[39m     attempts,\n\u001b[32m    202\u001b[39m     operation_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m     exception,\n\u001b[32m    206\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/endpoint.py:132\u001b[39m, in \u001b[36mEndpoint.create_request\u001b[39m\u001b[34m(self, params, operation_model)\u001b[39m\n\u001b[32m    130\u001b[39m     service_id = operation_model.service_model.service_id.hyphenize()\n\u001b[32m    131\u001b[39m     event_name = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mrequest-created.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_model.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event_emitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperation_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m prepared_request = \u001b[38;5;28mself\u001b[39m.prepare_request(request)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prepared_request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/hooks.py:412\u001b[39m, in \u001b[36mEventAliaser.emit\u001b[39m\u001b[34m(self, event_name, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34memit\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name, **kwargs):\n\u001b[32m    411\u001b[39m     aliased_event_name = \u001b[38;5;28mself\u001b[39m._alias_event_name(event_name)\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_emitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\u001b[43maliased_event_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/hooks.py:256\u001b[39m, in \u001b[36mHierarchicalEmitter.emit\u001b[39m\u001b[34m(self, event_name, **kwargs)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34memit\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name, **kwargs):\n\u001b[32m    246\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03m    Emit an event by name with arguments passed as keyword args.\u001b[39;00m\n\u001b[32m    248\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    254\u001b[39m \u001b[33;03m             handlers.\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_emit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/hooks.py:239\u001b[39m, in \u001b[36mHierarchicalEmitter._emit\u001b[39m\u001b[34m(self, event_name, kwargs, stop_on_response)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers_to_call:\n\u001b[32m    238\u001b[39m     logger.debug(\u001b[33m'\u001b[39m\u001b[33mEvent \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: calling handler \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m, event_name, handler)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     response = \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     responses.append((handler, response))\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stop_on_response \u001b[38;5;129;01mand\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/signers.py:106\u001b[39m, in \u001b[36mRequestSigner.handler\u001b[39m\u001b[34m(self, operation_name, request, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandler\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_name=\u001b[38;5;28;01mNone\u001b[39;00m, request=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# This is typically hooked up to the \"request-created\" event\u001b[39;00m\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# from a client's event emitter.  When a new request is created\u001b[39;00m\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# this method is invoked to sign the request.\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# Don't call this method directly.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msign\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/signers.py:198\u001b[39m, in \u001b[36mRequestSigner.sign\u001b[39m\u001b[34m(self, operation_name, request, region_name, signing_type, expires_in, signing_name)\u001b[39m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finetune-model/lib/python3.13/site-packages/botocore/auth.py:424\u001b[39m, in \u001b[36mSigV4Auth.add_auth\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_auth\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[32m    423\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NoCredentialsError()\n\u001b[32m    425\u001b[39m     datetime_now = datetime.datetime.utcnow()\n\u001b[32m    426\u001b[39m     request.context[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m] = datetime_now.strftime(SIGV4_TIMESTAMP)\n",
      "\u001b[31mNoCredentialsError\u001b[39m: Unable to locate credentials"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "# Upload function\n",
    "def upload_to_s3(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket inside a specific folder\"\"\"\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    s3.upload_file(file_name, bucket, object_name)\n",
    "    print(f\"File '{file_name}' uploaded successfully to '{bucket}/{object_name}'\")\n",
    "    return True\n",
    "\n",
    "# Local file path\n",
    "file_names = ['data/train.jsonl', 'data/test.jsonl', 'data/valid.jsonl']\n",
    "\n",
    "# S3 bucket name and S3 folder\n",
    "bucket_name = 'finetune-model-layer'\n",
    "s3_folder = 'data'  # This is the folder in the S3 bucket\n",
    "\n",
    "for file_name in file_names:\n",
    "    # Specify the full S3 object name (key)\n",
    "    object_name = f\"{s3_folder}/{file_name.split('/')[-1]}\"\n",
    "\n",
    "    # Upload the file to S3\n",
    "    upload_to_s3(file_name, bucket_name, object_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"google/gemma-2-2b-it\"\n",
    "command = [\n",
    "    'python', '-m', 'mlx_lm.convert', '--hf-path', model , '-q'\n",
    "]\n",
    "subprocess.run(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lora layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define variables\n",
    "model = \"mlx_model\"\n",
    "iters = 10\n",
    "steps_per_eval = 20\n",
    "val_batches = -1\n",
    "learning_rate = 1e-5\n",
    "adapter_path = \"adapter-2\"\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "# Define MLflow experiment\n",
    "mlflow.set_experiment(\"MLX LoRA Fine-Tuning\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"MLX-Model-LoRA-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"):\n",
    "\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param(\"model\", model)\n",
    "    mlflow.log_param(\"iters\", iters)\n",
    "    mlflow.log_param(\"steps_per_eval\", steps_per_eval)\n",
    "    mlflow.log_param(\"val_batches\", val_batches)\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"adapter_path\", adapter_path)\n",
    "\n",
    "    # Create the command list\n",
    "    command = [\n",
    "        'python', '-m', 'mlx_lm.lora', '--model', model, '--train',\n",
    "        '--iters', str(iters),\n",
    "        '--steps-per-eval', str(steps_per_eval),\n",
    "        '--val-batches', str(val_batches),\n",
    "        '--learning-rate', str(learning_rate),\n",
    "        '--test', \n",
    "        '--adapter-path', adapter_path\n",
    "    ]\n",
    "    \n",
    "    # Run the subprocess command to execute fine-tuning\n",
    "    subprocess.run(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store lora layer at s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the S3 client\n",
    "s3 = boto3.client(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "# Upload function\n",
    "def upload_to_s3(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket inside a specific folder\"\"\"\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    s3.upload_file(file_name, bucket, object_name)\n",
    "    print(f\"File '{file_name}' uploaded successfully to '{bucket}/{object_name}'\")\n",
    "    return True\n",
    "\n",
    "# Local file path\n",
    "folder_name = 'adapters'\n",
    "\n",
    "# S3 bucket name and S3 folder\n",
    "bucket_name = 'finetune-model-layer'\n",
    "s3_folder = 'lora_layer'  # This is the folder in the S3 bucket\n",
    "\n",
    "# Loop through all files in the adapters folder\n",
    "for root, dirs, files in os.walk(folder_name):\n",
    "    for file in files:\n",
    "        # Get the full file path\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        # Create the object name by preserving the folder structure\n",
    "        object_name = os.path.join(s3_folder, os.path.relpath(file_path, folder_name)).replace(\"\\\\\", \"/\")\n",
    "        \n",
    "        # Upload the file to S3\n",
    "        upload_to_s3(file_path, bucket_name, object_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the ai (human evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt format\n",
    "intstructions_string = f\"\"\"MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always provide the students steps to solve the question before provide answer. \\\n",
    "It reacts to feedback aptly and ends responses with its signature 'MathGPT'. \\\n",
    "MathGPT will tailor the length of its responses to match the student's questions, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\n",
    "\n",
    "Please respond to the following comment.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = lambda comment: f'''<s>[INST] {intstructions_string} \\n{comment} \\n[/INST]\\n'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define variables\n",
    "comment = \"In 1992, a scoop of gelato could be purchased in Italy for 1200 lire. The same gelato would have cost $\\\\$1.50$ in the U.S. At the equivalent exchange rate between the lire and the dollar, how many dollars would be equivalent to 1,000,000 lire?\"\n",
    "\n",
    "# Generate the prompt using the comment\n",
    "prompt = prompt_template(comment)\n",
    "\n",
    "# Create the command list\n",
    "command = [\n",
    "    'python', '-m', 'mlx_lm.generate',\n",
    "    '--model', 'mlx_model',\n",
    "    '--adapter-path', 'adapters',\n",
    "    '--max-tokens', '512',\n",
    "    '--prompt', prompt\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "comment = \"In 1992, a scoop of gelato could be purchased in Italy for 1200 lire. The same gelato would have cost $\\\\$1.50$ in the U.S. At the equivalent exchange rate between the lire and the dollar, how many dollars would be equivalent to 1,000,000 lire?\"\n",
    "\n",
    "# Generate the prompt using the comment\n",
    "prompt = prompt_template(comment)\n",
    "\n",
    "# Create the command list\n",
    "command = [\n",
    "    'python', '-m', 'mlx_lm.generate',\n",
    "    '--model', 'mlx_model',\n",
    "    '--max-tokens', '512',\n",
    "    '--prompt', prompt\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the response with openai and store in MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>By the associative property of multiplication,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Since $10^x - 10 = 9990,$ we have $$10^x = 999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Squaring both sides, we get\\n\\[x + \\sqrt{3x + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Setting $x = 0,$ we get $|c| \\le 1.$  Setting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Let $\\mathbf{v} = \\begin{pmatrix} a \\\\ b \\\\ c ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>We count the number of times $\\frac{1}{n^3}$ a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>We can write\\n\\begin{align*}\\n\\frac{1}{\\cos^2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Let $s_1 = x + y + z$ and $s_2 = xy + xz + yz....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>The hexagon has a side length of 16 centimeter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MathGPT, functioning as a virtual Math chatbot...</td>\n",
       "      <td>Suppose that $\\angle ADC = x^\\circ$. The area ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs  \\\n",
       "0  MathGPT, functioning as a virtual Math chatbot...   \n",
       "1  MathGPT, functioning as a virtual Math chatbot...   \n",
       "2  MathGPT, functioning as a virtual Math chatbot...   \n",
       "3  MathGPT, functioning as a virtual Math chatbot...   \n",
       "4  MathGPT, functioning as a virtual Math chatbot...   \n",
       "5  MathGPT, functioning as a virtual Math chatbot...   \n",
       "6  MathGPT, functioning as a virtual Math chatbot...   \n",
       "7  MathGPT, functioning as a virtual Math chatbot...   \n",
       "8  MathGPT, functioning as a virtual Math chatbot...   \n",
       "9  MathGPT, functioning as a virtual Math chatbot...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  By the associative property of multiplication,...  \n",
       "1  Since $10^x - 10 = 9990,$ we have $$10^x = 999...  \n",
       "2  Squaring both sides, we get\\n\\[x + \\sqrt{3x + ...  \n",
       "3  Setting $x = 0,$ we get $|c| \\le 1.$  Setting ...  \n",
       "4  Let $\\mathbf{v} = \\begin{pmatrix} a \\\\ b \\\\ c ...  \n",
       "5  We count the number of times $\\frac{1}{n^3}$ a...  \n",
       "6  We can write\\n\\begin{align*}\\n\\frac{1}{\\cos^2 ...  \n",
       "7  Let $s_1 = x + y + z$ and $s_2 = xy + xz + yz....  \n",
       "8  The hexagon has a side length of 16 centimeter...  \n",
       "9  Suppose that $\\angle ADC = x^\\circ$. The area ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the test dataset (without the response)\n",
    "inputs = []\n",
    "ground_truth = []\n",
    "\n",
    "# Go through each example in test_list\n",
    "for example in test_list:\n",
    "    # Extract the comment part from the 'text' field (everything between [INST] and [/INST])\n",
    "    inst_start = example['text'].find(\"[INST]\") + len(\"[INST]\")\n",
    "    inst_end = example['text'].find(\"[/INST]\")\n",
    "\n",
    "    # Extract the comment (instruction) and the response\n",
    "    questions = example['text'][inst_start:inst_end].strip()  # This is the prompt for the test data\n",
    "    response = example['text'][inst_end + len(\"[/INST]\"):-4].strip()  # This is the corresponding answer\n",
    "\n",
    "    # Append to inputs and ground truth\n",
    "    inputs.append(questions)\n",
    "    ground_truth.append(response)\n",
    "\n",
    "# Convert inputs and ground_truth to a DataFrame\n",
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"inputs\": inputs,        \n",
    "        \"ground_truth\": ground_truth\n",
    "    }\n",
    ")\n",
    "\n",
    "# Example to see the eval_data\n",
    "eval_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the structure of MLX model in MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wongyenchik/anaconda3/envs/finetune-model/lib/python3.13/site-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "import subprocess\n",
    "\n",
    "class MLXModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        # Store the model path, which will be used later in the prediction step\n",
    "        self.model_path = context.artifacts[\"model\"]\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        # Log the input type\n",
    "        print(f\"Input type: {type(model_input)}\")\n",
    "        print(f\"Input data: {model_input}\")\n",
    "\n",
    "        # Check if the input is a DataFrame and extract the 'inputs' column\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            if 'inputs' in model_input.columns:\n",
    "                # Loop through the DataFrame and process each row\n",
    "                responses = []\n",
    "                for comment in model_input['inputs']:\n",
    "                    prompt = self.prompt_template(comment)\n",
    "\n",
    "                    command = [\n",
    "                        'python', '-m', 'mlx_lm.generate',\n",
    "                        '--model', self.model_path,  # Use the stored model path from load_context\n",
    "                        '--max-tokens', '512',\n",
    "                        '--prompt', prompt\n",
    "                    ]\n",
    "\n",
    "                    # Run the command to generate the response\n",
    "                    result = subprocess.run(command, capture_output=True, text=True)\n",
    "                    responses.append(result.stdout)\n",
    "                return responses\n",
    "            else:\n",
    "                raise ValueError(\"Expected 'inputs' column in the DataFrame.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected input type: {type(model_input)}\")\n",
    "\n",
    "    def prompt_template(self, comment):\n",
    "        # Custom prompt template\n",
    "        instructions_string = \"\"\"MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always providing the students steps to solve the question before providing the answer. \\\n",
    "It reacts to feedback aptly and ends responses with its signature 'MathGPT'. \\\n",
    "MathGPT will tailor the length of its responses to match the student's questions, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\n",
    "Please respond to the following comment.\n",
    "\"\"\"\n",
    "        return f'''<s>[INST] {instructions_string} \\n{comment} \\n[/INST]\\n'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log the model in MLFlow and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 22:29:07 INFO mlflow.tracking.fluent: Experiment with name 'LLM Evaluation' does not exist. Creating a new experiment.\n",
      "2025/03/05 22:29:07 INFO mlflow.pyfunc: Validating input example against model signature\n",
      "Downloading artifacts: 100%|██████████| 25/25 [00:01<00:00, 15.22it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "0  [INST] MathGPT, functioning as a virtual Math ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 32/32 [00:30<00:00,  1.06it/s]  \n",
      "2025/03/05 22:30:15 INFO mlflow.models.evaluation.utils.trace: Auto tracing is temporarily enabled during the model evaluation for computing some metrics and debugging. To disable tracing, call `mlflow.autolog(disable=True)`.\n",
      "2025/03/05 22:30:15 INFO mlflow.models.evaluation.evaluators.default: Computing model predictions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "0  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "1  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "2  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "3  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "4  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "5  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "6  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "7  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "8  MathGPT, functioning as a virtual Math chatbot...\n",
      "Input type: <class 'pandas.core.frame.DataFrame'>\n",
      "Input data:                                               inputs\n",
      "9  MathGPT, functioning as a virtual Math chatbot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 22:34:42 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "Device set to use mps:0\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n",
      "100%|██████████| 10/10 [00:09<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlflow.models.evaluation.base.EvaluationResult object at 0x2ae240cd0>\n",
      "🏃 View run mysterious-midge-856 at: http://127.0.0.1:5000/#/experiments/880270386239245598/runs/963ef29d73b34430959321a914b68a5e\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/880270386239245598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mlflow.metrics import latency\n",
    "from mlflow.metrics.genai import answer_correctness\n",
    "import time\n",
    "import mlflow\n",
    "signature = mlflow.models.infer_signature(\n",
    "    model_input=pd.DataFrame({\n",
    "    'inputs': [\n",
    "        \"[INST] MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always providing steps before the answer. ...\",\n",
    "    ]\n",
    "}),\n",
    "    model_output=[\"==========\\nLet's solve that!  \\n\\nTo find the answer, we simply add the numbers together: 4 + 4 = 8. \\n\\nSo, 4 + 4 = 8. \\n\\nMathGPT \\n\\n==========\\nPrompt: 119 tokens, 102.358 tokens-per-sec\\nGeneration: 49 tokens, 15.268 tokens-per-sec\\nPeak memory: 1.713 GB\\n\",\n",
    " \"==========\\nTo find the derivative of x², we use the power rule of differentiation.  \\n\\nThe power rule states that the derivative of x<sup>n</sup> is nx<sup>n-1</sup>.\\n\\nApplying this to x²:\\n\\n*  The derivative of x² is 2x<sup>2-1</sup> \\n*  Simplifying, we get 2x<sup>1</sup> \\n*  Therefore, the derivative of x² is **2x**. \\n\\n\\nMathGPT \\n\\n==========\\nPrompt: 120 tokens, 118.289 tokens-per-sec\\nGeneration: 99 tokens, 18.342 tokens-per-sec\\nPeak memory: 1.714 GB\\n\"],\n",
    ")\n",
    "input_example = pd.DataFrame({\n",
    "    'inputs': [\n",
    "        \"[INST] MathGPT, functioning as a virtual Math chatbot, communicates in clear, accessible language, always providing steps before the answer. ...\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "# The evaluation process remains the same\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "mlflow.set_experiment(\"LLM Evaluation\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    logged_model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",  # Path where the model will be stored in MLflow\n",
    "        python_model=MLXModelWrapper(),  # Your custom model wrapper\n",
    "        artifacts={\"model\": \"/Users/wongyenchik/Desktop/finetune llama/my-model\"},  # The path to your saved MLX model\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )\n",
    "\n",
    "    # Use the function to evaluate the model\n",
    "    results = mlflow.evaluate(\n",
    "        logged_model_info.model_uri,\n",
    "        data=eval_data[:10],\n",
    "        targets=\"ground_truth\",\n",
    "        model_type=\"question-answering\",\n",
    "        extra_metrics=[\n",
    "            answer_correctness(),\n",
    "            latency(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Example output DataFrame for inspection\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model and push to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "save_path = \"my-model\"\n",
    "\n",
    "# Create the command list\n",
    "command = [\n",
    "    'python', '-m', 'mlx_lm.fuse',\n",
    "    '--model', 'mlx_model',\n",
    "    '--save-path', save_path,\n",
    "    '--adapter-path', 'adapters',\n",
    "    '--upload-repo', 'yenchik/mlx-gemma-2-2b-it-math',\n",
    "    '--hf-path', 'google/gemma-2-2b-it'\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "subprocess.run(command)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load(\"yenchik/mlx-gemma-2-2b-it-math\")\n",
    "\n",
    "prompt = \"In 1992, a scoop of gelato could be purchased in Italy for 1200 lire. The same gelato would have cost $\\\\$1.50$ in the U.S. At the equivalent exchange rate between the lire and the dollar, how many dollars would be equivalent to 1,000,000 lire?\"\n",
    "if tokenizer.chat_template is not None:\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
